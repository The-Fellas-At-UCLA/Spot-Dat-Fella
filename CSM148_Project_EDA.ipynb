{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QcMMxAgO_X8c"
   },
   "source": [
    "\n",
    "# Setup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3bvoIdo1MAsJ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.mode.copy_on_write = True\n",
    "\n",
    "# Using the URL for the file\n",
    "spotify_original = pd.read_csv(\"spotify_data/dataset.csv\")\n",
    "\n",
    "spotify_original_reshape = spotify_original.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ex-ehlXvYZbH"
   },
   "source": [
    "# Data Cleaning\n",
    "\n",
    "\n",
    "*   Todo 1\n",
    "*   Todo 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 163,
     "status": "ok",
     "timestamp": 1728671738991,
     "user": {
      "displayName": "PAUL CANO",
      "userId": "16231630220263022191"
     },
     "user_tz": 420
    },
    "id": "YqYMe6nK0WLg",
    "outputId": "61c9b59c-88c3-406d-cad7-b75f45b5b948"
   },
   "outputs": [],
   "source": [
    "#spotify_original_reshape.head(20)\n",
    "#spotify_original.shape\n",
    "spotify_original_reshape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "executionInfo": {
     "elapsed": 167,
     "status": "ok",
     "timestamp": 1728672778508,
     "user": {
      "displayName": "PAUL CANO",
      "userId": "16231630220263022191"
     },
     "user_tz": 420
    },
    "id": "2k0uIm_Y7R5m",
    "outputId": "2fb8b216-1c1d-48c6-ddce-c4d7e957d668"
   },
   "outputs": [],
   "source": [
    "spotify_original_reshape['track_name'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "executionInfo": {
     "elapsed": 200,
     "status": "ok",
     "timestamp": 1728672723942,
     "user": {
      "displayName": "PAUL CANO",
      "userId": "16231630220263022191"
     },
     "user_tz": 420
    },
    "id": "FaIOFCNvMA69",
    "outputId": "c7125beb-7a89-493e-fb70-1388ea3183e9"
   },
   "outputs": [],
   "source": [
    "spotify_original_reshape['popularity'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "executionInfo": {
     "elapsed": 158,
     "status": "ok",
     "timestamp": 1728672848289,
     "user": {
      "displayName": "PAUL CANO",
      "userId": "16231630220263022191"
     },
     "user_tz": 420
    },
    "id": "QRHg7rmTMBD_",
    "outputId": "6be119ba-1434-4067-cc04-74cbc14d6795"
   },
   "outputs": [],
   "source": [
    "spotify_original_reshape['track_genre'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 525,
     "status": "ok",
     "timestamp": 1728675288832,
     "user": {
      "displayName": "PAUL CANO",
      "userId": "16231630220263022191"
     },
     "user_tz": 420
    },
    "id": "UGZ8pMoLExvK",
    "outputId": "2189e617-9f20-4833-83c4-74f23e43a8f7"
   },
   "outputs": [],
   "source": [
    "missing_track = spotify_original_reshape[spotify_original_reshape['track_id'] == '1kR4gIb7nGxHPI3D2ifs59']\n",
    "print(missing_track)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 297,
     "status": "ok",
     "timestamp": 1728755806807,
     "user": {
      "displayName": "SHAFEE KHAN",
      "userId": "10219242836598942056"
     },
     "user_tz": 420
    },
    "id": "yBslr9RFK4D4",
    "outputId": "b290b10a-6464-41b1-ab51-fe28ebd93161"
   },
   "outputs": [],
   "source": [
    "# Cleaning rows with missing information\n",
    "missing_data_rows = spotify_original_reshape[spotify_original_reshape.isnull().any(axis=1)]\n",
    "\n",
    "missing_data_rows\n",
    "\n",
    "spotify_original_reshape_drop = spotify_original_reshape.dropna()\n",
    "\n",
    "print(spotify_original_reshape.shape)\n",
    "print(spotify_original_reshape_drop.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 221,
     "status": "ok",
     "timestamp": 1728755928926,
     "user": {
      "displayName": "SHAFEE KHAN",
      "userId": "10219242836598942056"
     },
     "user_tz": 420
    },
    "id": "2xASmZeljbVN",
    "outputId": "3340b028-92e1-4ef3-b247-63957fa81263"
   },
   "outputs": [],
   "source": [
    "#clean track_name and artists columns by stripping spaces and converting to lowercase\n",
    "spotify_original_reshape_drop['track_name_clean'] = spotify_original_reshape_drop['track_name'].str.strip().str.lower()\n",
    "spotify_original_reshape_drop['artists_clean'] = spotify_original_reshape_drop['artists'].str.strip().str.lower()\n",
    "\n",
    "#priority list for genres to handle duplicates\n",
    "genre_priority = ['pop', 'rock', 'hip hop', 'rap', 'reggaeton', 'latin', 'electronic', 'r&b', 'reggae', 'dance', 'classical']\n",
    "spotify_original_reshape_drop['genre_priority'] = spotify_original_reshape_drop['track_genre'].apply(lambda x: genre_priority.index(x) if x in genre_priority else len(genre_priority))\n",
    "\n",
    "#sort the dataset by track_name, artists, genre priority, popularity, and duration\n",
    "spotify_data_sorted = spotify_original_reshape_drop.sort_values(by=['track_name_clean', 'artists_clean', 'genre_priority', 'popularity', 'duration_ms'],\n",
    "                                                                ascending=[True, True, True, True, False])\n",
    "\n",
    "#remove duplicates\n",
    "spotify_cleaned = spotify_data_sorted.drop_duplicates(subset=['track_name_clean', 'artists_clean'], keep='first')\n",
    "\n",
    "# checking size\n",
    "print(f\"Shape of the dataset before cleaning: {spotify_original_reshape_drop.shape}\")\n",
    "print(f\"Shape of the dataset after cleaning: {spotify_cleaned.shape}\")\n",
    "\n",
    "# removing extra columns added\n",
    "spotify_cleaned_final = spotify_cleaned.drop(columns=['track_name_clean', 'artists_clean', 'genre_priority'])\n",
    "\n",
    "# Fcheck size again\n",
    "print(f\"Shape of the dataset after removing extra columns: {spotify_cleaned_final.shape}\")\n",
    "\n",
    "\n",
    "spotify_cleaned_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation matrix with target being Danceability\n",
    "\n",
    "numeric_data = spotify_cleaned_final.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "correlation_matrix = numeric_data.corr()\n",
    "\n",
    "danceability_correlation = correlation_matrix[\"danceability\"].sort_values(ascending=False)\n",
    "\n",
    "print(danceability_correlation)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Create a heatmap to visualize correlations\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Correlation Heatmap for Spotify Dataset')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "\n",
    "X_loudness = spotify_cleaned_final.select_dtypes(include=['float64', 'int64']).drop(columns=['energy'])\n",
    "y_energy = spotify_cleaned_final['energy']\n",
    "\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_loudness, y_energy, test_size=1/3, random_state=35)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.5, random_state=35)\n",
    "\n",
    "# polynomial transformation to the features (degree=2)\n",
    "poly = PolynomialFeatures(degree=1)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_val_poly = poly.transform(X_val)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "# train the linear regression model using the transformed polynomial features\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_poly, y_train)\n",
    "\n",
    "print(\"Coefficients (Theta):\", model.coef_)\n",
    "\n",
    "print(\"Columns\", X_loudness.columns)\n",
    "\n",
    "# evaluate on validation set\n",
    "y_pred_val = model.predict(X_val_poly)\n",
    "mse_val = mean_squared_error(y_val, y_pred_val)\n",
    "r2_val = r2_score(y_val, y_pred_val)\n",
    "print(f\"Mean Squared Error (Validation Data): {mse_val}\")\n",
    "print(f\"R-squared (Validation Data): {r2_val}\")\n",
    "\n",
    "# once validated, evaluate on the test set (unseen data)\n",
    "y_pred_test = model.predict(X_test_poly)\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "print(f\"Mean Squared Error (Test Data): {mse_test}\")\n",
    "print(f\"R-squared (Test Data): {r2_test}\")\n",
    "\n",
    "# Check the shape of the splits\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_val shape: {y_val.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate residuals for the test set\n",
    "residuals = y_test - y_pred_test\n",
    "\n",
    "# Scatter plot of residuals\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_pred_test, residuals, color='blue', alpha=0.3)\n",
    "plt.axhline(y=0, color='red', linestyle='--')\n",
    "plt.xlabel('Predicted Energy')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residuals Plot')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Step 1: Polynomial transformation (you've already done this)\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_val_poly = poly.transform(X_val)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "# Step 2: Initialize and fit the Lasso regression model\n",
    "lasso_model = Lasso(alpha=0.005)  # You can tune the alpha value\n",
    "lasso_model.fit(X_train_poly, y_train)\n",
    "\n",
    "# Step 3: Predict on validation and test sets\n",
    "y_pred_val_lasso = lasso_model.predict(X_val_poly)\n",
    "y_pred_test_lasso = lasso_model.predict(X_test_poly)\n",
    "\n",
    "# Step 4: Evaluate the model performance\n",
    "mse_val_lasso = mean_squared_error(y_val, y_pred_val_lasso)\n",
    "r2_val_lasso = r2_score(y_val, y_pred_val_lasso)\n",
    "print(f\"Lasso - Mean Squared Error (Validation Data): {mse_val_lasso}\")\n",
    "print(f\"Lasso - R-squared (Validation Data): {r2_val_lasso}\")\n",
    "\n",
    "mse_test_lasso = mean_squared_error(y_test, y_pred_test_lasso)\n",
    "r2_test_lasso = r2_score(y_test, y_pred_test_lasso)\n",
    "print(f\"Lasso - Mean Squared Error (Test Data): {mse_test_lasso}\")\n",
    "print(f\"Lasso - R-squared (Test Data): {r2_test_lasso}\")\n",
    "\n",
    "# Step 5: Analyze residuals for Lasso model\n",
    "residuals_lasso = y_test - y_pred_test_lasso\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_pred_test_lasso, residuals_lasso, color='blue', alpha=0.3)\n",
    "plt.axhline(y=0, color='red', linestyle='--')\n",
    "plt.xlabel('Predicted Energy (Lasso)')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residuals Plot for Lasso Regression')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "X_loudness = numeric_data[['loudness']]\n",
    "y_energy = numeric_data['energy']\n",
    "\n",
    "\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_loudness, y_energy, test_size=1/3, random_state=35)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.5, random_state=35)\n",
    "\n",
    "# polynomial transformation to the features (degree=2)\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_val_poly = poly.transform(X_val)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "# train the linear regression model using the transformed polynomial features\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_poly, y_train)\n",
    "\n",
    "# evaluate on validation set\n",
    "y_pred_val = model.predict(X_val_poly)\n",
    "mse_val = mean_squared_error(y_val, y_pred_val)\n",
    "r2_val = r2_score(y_val, y_pred_val)\n",
    "print(f\"Mean Squared Error (Validation Data): {mse_val}\")\n",
    "print(f\"R-squared (Validation Data): {r2_val}\")\n",
    "\n",
    "# once validated, evaluate on the test set (unseen data)\n",
    "y_pred_test = model.predict(X_test_poly)\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "print(f\"Mean Squared Error (Test Data): {mse_test}\")\n",
    "print(f\"R-squared (Test Data): {r2_test}\")\n",
    "\n",
    "# plot the validation data points and regression line\n",
    "plt.scatter(X_val, y_val, color='green', label='Validation Data points', s=10, alpha=0.3)\n",
    "sorted_idx = np.argsort(X_val.values.flatten())\n",
    "plt.plot(X_val.values[sorted_idx], y_pred_val[sorted_idx], color='orange', linewidth=2, label='Polynomial regression line (Validation)')\n",
    "\n",
    "plt.xticks(np.arange(min(X_val.values), max(X_val.values)+1, 2), rotation=45, fontsize=10)\n",
    "plt.yticks(np.arange(0, 1.01, 0.1))\n",
    "\n",
    "plt.xlabel('Loudness')\n",
    "plt.ylabel('Energy (scale 0-1)')\n",
    "plt.title('Energy vs Loudness with Polynomial Regression Line (Validation Data)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# plot the test data points and regression line\n",
    "plt.scatter(X_test, y_test, color='blue', label='Test Data points', s=10, alpha=0.3)\n",
    "sorted_idx = np.argsort(X_test.values.flatten())\n",
    "plt.plot(X_test.values[sorted_idx], y_pred_test[sorted_idx], color='red', linewidth=2, label='Polynomial regression line (Test)')\n",
    "\n",
    "plt.xticks(np.arange(min(X_test.values), max(X_test.values)+1, 2), rotation=45, fontsize=10)\n",
    "plt.yticks(np.arange(0, 1.01, 0.1))\n",
    "\n",
    "plt.xlabel('Loudness')\n",
    "plt.ylabel('Energy (scale 0-1)')\n",
    "plt.title('Energy vs Loudness with Polynomial Regression Line (Test Data)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Check the shape of the splits\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_val shape: {y_val.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Select additional features along with loudness\n",
    "X_features = numeric_data[['loudness', 'tempo', 'valence', 'danceability']]  # Add relevant features\n",
    "y_energy = numeric_data['energy']\n",
    "\n",
    "# Step 2: Split the data into training, validation, and test sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_features, y_energy, test_size=1/3, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.5, random_state=42)\n",
    "\n",
    "# Step 3: Apply polynomial transformation (degree=2 or 3) on multiple features\n",
    "poly = PolynomialFeatures(degree=2)  # You can change to degree 3 if needed\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_val_poly = poly.transform(X_val)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "# Step 4: Train a Ridge regression model\n",
    "ridge_model = Ridge(alpha=1.0)  # You can tune the alpha parameter\n",
    "ridge_model.fit(X_train_poly, y_train)\n",
    "\n",
    "# Step 5: Predict on validation and test sets\n",
    "y_pred_val_ridge = ridge_model.predict(X_val_poly)\n",
    "y_pred_test_ridge = ridge_model.predict(X_test_poly)\n",
    "\n",
    "# Step 6: Evaluate the model performance\n",
    "mse_val_ridge = mean_squared_error(y_val, y_pred_val_ridge)\n",
    "r2_val_ridge = r2_score(y_val, y_pred_val_ridge)\n",
    "print(f\"Ridge - Mean Squared Error (Validation Data): {mse_val_ridge}\")\n",
    "print(f\"Ridge - R-squared (Validation Data): {r2_val_ridge}\")\n",
    "\n",
    "mse_test_ridge = mean_squared_error(y_test, y_pred_test_ridge)\n",
    "r2_test_ridge = r2_score(y_test, y_pred_test_ridge)\n",
    "print(f\"Ridge - Mean Squared Error (Test Data): {mse_test_ridge}\")\n",
    "print(f\"Ridge - R-squared (Test Data): {r2_test_ridge}\")\n",
    "\n",
    "# Step 7: Plot the residuals for Ridge regression on the test set\n",
    "residuals_ridge = y_test - y_pred_test_ridge\n",
    "plt.scatter(X_test['loudness'], residuals_ridge)  # Scatter plot against loudness\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Loudness')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residuals Plot for Ridge Regression with Additional Features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],         # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30],        # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 10, 20]        # Minimum number of samples required to split\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest Regressor\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Perform grid search with cross-validation (cv=3)\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, scoring='r2', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters from grid search\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "# Evaluate the best model\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on validation and test sets\n",
    "y_pred_val_best_rf = best_rf_model.predict(X_val)\n",
    "y_pred_test_best_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "mse_val_best_rf = mean_squared_error(y_val, y_pred_val_best_rf)\n",
    "r2_val_best_rf = r2_score(y_val, y_pred_val_best_rf)\n",
    "print(f\"Best Random Forest - Mean Squared Error (Validation Data): {mse_val_best_rf}\")\n",
    "print(f\"Best Random Forest - R-squared (Validation Data): {r2_val_best_rf}\")\n",
    "\n",
    "mse_test_best_rf = mean_squared_error(y_test, y_pred_test_best_rf)\n",
    "r2_test_best_rf = r2_score(y_test, y_pred_test_best_rf)\n",
    "print(f\"Best Random Forest - Mean Squared Error (Test Data): {mse_test_best_rf}\")\n",
    "print(f\"Best Random Forest - R-squared (Test Data): {r2_test_best_rf}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "importances = best_rf_model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Feature Importances (Best Random Forest)\")\n",
    "plt.bar(range(X_train.shape[1]), importances[indices], align=\"center\")\n",
    "plt.xticks(range(X_train.shape[1]), X_train.columns[indices], rotation=90)\n",
    "plt.ylabel('Importance')\n",
    "plt.show()\n",
    "\n",
    "# Validation set plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_val, y_pred_val_best_rf, color='green', alpha=0.3, label='Predicted vs Actual')\n",
    "plt.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], color='red', lw=2, label='Perfect Fit Line')\n",
    "plt.xlabel('Actual Energy')\n",
    "plt.ylabel('Predicted Energy')\n",
    "plt.title('Validation Data: Actual vs Predicted Energy (Best Random Forest)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Test set plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred_test_best_rf, color='blue', alpha=0.3, label='Predicted vs Actual')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', lw=2, label='Perfect Fit Line')\n",
    "plt.xlabel('Actual Energy')\n",
    "plt.ylabel('Predicted Energy')\n",
    "plt.title('Test Data: Actual vs Predicted Energy (Best Random Forest)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Plot the actual vs predicted for Validation set\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_val, y_pred_val_ridge, color='green', alpha=0.3, label='Predicted vs Actual')\n",
    "plt.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], color='red', lw=2, label='Perfect Fit Line')\n",
    "plt.xlabel('Actual Energy')\n",
    "plt.ylabel('Predicted Energy')\n",
    "plt.title('Validation Data: Actual vs Predicted Energy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Step 2: Plot the actual vs predicted for Test set\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred_test_ridge, color='blue', alpha=0.3, label='Predicted vs Actual')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', lw=2, label='Perfect Fit Line')\n",
    "plt.xlabel('Actual Energy')\n",
    "plt.ylabel('Predicted Energy')\n",
    "plt.title('Test Data: Actual vs Predicted Energy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_test - y_pred_test\n",
    "plt.scatter(X_test, residuals)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Loudness')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residuals Plot')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4WK1C3rzANxG"
   },
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "\n",
    "*   Todo 1\n",
    "*   Todo 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "executionInfo": {
     "elapsed": 775,
     "status": "ok",
     "timestamp": 1728672579553,
     "user": {
      "displayName": "PAUL CANO",
      "userId": "16231630220263022191"
     },
     "user_tz": 420
    },
    "id": "aca4HVPZ543-",
    "outputId": "3fd4abdc-6ebb-4947-e72a-1ec5b6d4810b"
   },
   "outputs": [],
   "source": [
    "spotify_original_reshape['liveness'].hist(bins = 30, alpha = 0.5, color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1728675072745,
     "user": {
      "displayName": "PAUL CANO",
      "userId": "16231630220263022191"
     },
     "user_tz": 420
    },
    "id": "SLHOJ7WGB0Gb",
    "outputId": "536e1583-d161-46a2-944a-f6e979574ce4"
   },
   "outputs": [],
   "source": [
    "\"Visualizing correlation between features\"\n",
    "\n",
    "plt.scatter(spotify_original_reshape['danceability'], spotify_original_reshape['popularity'], s = 0.1)\n",
    "plt.xlabel('Danceability')\n",
    "plt.ylabel('Popularity')\n",
    "plt.title('Danceability vs Popularity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "executionInfo": {
     "elapsed": 802,
     "status": "ok",
     "timestamp": 1728675405574,
     "user": {
      "displayName": "PAUL CANO",
      "userId": "16231630220263022191"
     },
     "user_tz": 420
    },
    "id": "swljig2WFNDb",
    "outputId": "fbd5a8c4-6b30-4529-9b6b-328c3fd800da"
   },
   "outputs": [],
   "source": [
    "\"Visualizing correlation between features\"\n",
    "plt.scatter(spotify_original_reshape['energy'], spotify_original_reshape['popularity'], s = 0.1)\n",
    "plt.xlabel('Energy')\n",
    "plt.ylabel('Popularity')\n",
    "plt.title('Energy vs Popularity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 561,
     "status": "ok",
     "timestamp": 1728676132293,
     "user": {
      "displayName": "PAUL CANO",
      "userId": "16231630220263022191"
     },
     "user_tz": 420
    },
    "id": "5eKIrGgEF2Zh",
    "outputId": "dc9dbabb-e937-488e-d941-9a7358cab4fe"
   },
   "outputs": [],
   "source": [
    "#Finding the Correlation Between Popularity and other features\n",
    "\n",
    "for features in spotify_original_reshape.select_dtypes(include=[np.number]).columns:\n",
    "  print(features, 'vs. Popularity Correlation:', np.corrcoef(spotify_original_reshape['popularity'], spotify_original_reshape[features])[0,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 153,
     "status": "ok",
     "timestamp": 1728676225815,
     "user": {
      "displayName": "PAUL CANO",
      "userId": "16231630220263022191"
     },
     "user_tz": 420
    },
    "id": "XT_JFtOLIT3h",
    "outputId": "385e3a7d-17c1-4750-f50c-93cb12fead91"
   },
   "outputs": [],
   "source": [
    "#Finding the Correlation Between Tempo and other features\n",
    "\n",
    "for features in spotify_original_reshape.select_dtypes(include=[np.number]).columns:\n",
    "  print(features, 'vs. Tempo Correlation:', np.corrcoef(spotify_original_reshape['tempo'], spotify_original_reshape[features])[0,1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklego.linear_model import LADRegression\n",
    "\n",
    "ls_tempo_danceability_fit = LinearRegression()\n",
    "ls_tempo_danceability_fit.fit(X=np.array(spotify_original_reshape_drop['tempo']).reshape(-1, 1),\n",
    "                          y=spotify_original_reshape_drop['danceability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(spotify_original_reshape_drop, x='tempo', y='danceability')\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=spotify_original_reshape_drop['tempo'],\n",
    "                y=ls_tempo_danceability_fit.intercept_ + spotify_original_reshape_drop['tempo'] * ls_tempo_danceability_fit.coef_[0],\n",
    "                mode='lines',\n",
    "                name='LS',\n",
    "                line={'dash': 'solid',\n",
    "                      'color': 'black'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_df = pd.DataFrame(\n",
    "    {'true': spotify_original_reshape_drop['danceability'],\n",
    "     'ls_pred': ls_tempo_danceability_fit.predict(np.array(spotify_original_reshape_drop['tempo']).reshape(-1, 1))})\n",
    "pred_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the rMSE, MAE, MAD, correlation, and R2 of the true price with the LS predictions\n",
    "print('LS rMSE:', np.sqrt(mean_squared_error(pred_train_df['true'], pred_train_df['ls_pred'])))\n",
    "print('LS MAE:', mean_absolute_error(pred_train_df['true'], pred_train_df['ls_pred']))\n",
    "print('LS MAD:', np.median(np.abs(pred_train_df['true'] - pred_train_df['ls_pred'])))\n",
    "print('LS correlation:', np.corrcoef(pred_train_df['true'], pred_train_df['ls_pred'])[0, 1])\n",
    "print('LS R2:', r2_score(pred_train_df['true'], pred_train_df['ls_pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_loudness_energy_fit = LinearRegression()\n",
    "ls_loudness_energy_fit.fit(X=np.array(spotify_original_reshape_drop['loudness']).reshape(-1, 1),\n",
    "                          y=spotify_original_reshape_drop['energy'])\n",
    "\n",
    "fig = px.scatter(spotify_original_reshape_drop, x='loudness', y='energy')\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=spotify_original_reshape_drop['loudness'],\n",
    "                y=ls_loudness_energy_fit.intercept_ + spotify_original_reshape_drop['loudness'] * ls_loudness_energy_fit.coef_[0],\n",
    "                mode='lines',\n",
    "                name='LS',\n",
    "                line={'dash': 'solid',\n",
    "                      'color': 'black'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_df = pd.DataFrame(\n",
    "    {'true': spotify_original_reshape_drop['energy'],\n",
    "     'ls_pred': ls_loudness_energy_fit.predict(np.array(spotify_original_reshape_drop['loudness']).reshape(-1, 1))})\n",
    "pred_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the rMSE, MAE, MAD, correlation, and R2 of the true price with the LS predictions\n",
    "print('LS rMSE:', np.sqrt(mean_squared_error(pred_train_df['true'], pred_train_df['ls_pred'])))\n",
    "print('LS MAE:', mean_absolute_error(pred_train_df['true'], pred_train_df['ls_pred']))\n",
    "print('LS MAD:', np.median(np.abs(pred_train_df['true'] - pred_train_df['ls_pred'])))\n",
    "print('LS correlation:', np.corrcoef(pred_train_df['true'], pred_train_df['ls_pred'])[0, 1])\n",
    "print('LS R2:', r2_score(pred_train_df['true'], pred_train_df['ls_pred']))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "4WK1C3rzANxG"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
